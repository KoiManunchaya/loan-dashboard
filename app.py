import os
import pandas as pd
import numpy as np
import plotly.express as px

from dash import Dash, dcc, html, Input, Output, dash_table
import dash_bootstrap_components as dbc

# ========== Load & Prepare Data ==========

# --- Path ‡∏´‡∏•‡∏±‡∏Å (‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏•‡πá‡∏Å‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡∏Å‡∏•‡∏á)
MAIN_CSV = "data/clean_loan_small.csv"

def safe_read_csv(path, **kwargs):
    if os.path.exists(path):
        return pd.read_csv(path, **kwargs)
    return None

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å
if not os.path.exists(MAIN_CSV):
    raise FileNotFoundError(
        f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {MAIN_CSV} ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢ create_small_data.py ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ä‡πá‡∏Å path ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"
    )

df = pd.read_csv(MAIN_CSV)
df.columns = df.columns.str.strip().str.lower()

# ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏∑‡πà‡∏ô‡∏ï‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏° (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
feature_importance = safe_read_csv("data/feature_importance.csv")
feature_defs_csv = safe_read_csv("data/feature_definitions_filtered.csv")

# ----- Clean & map loan_status ‡πÄ‡∏õ‡πá‡∏ô 0/1 -----
if "loan_status" not in df.columns:
    raise ValueError("‚ùå Column 'loan_status' not found. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏ä‡πá‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

if df["loan_status"].dtype == object:
    df["loan_status"] = (
        df["loan_status"]
        .astype(str).str.strip().str.lower()
        .map({"fully paid": 0, "paid": 0, "charged off": 1, "default": 1})
        .fillna(0)
        .astype(int)
    )

# income_group (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å annual_inc)
if "income_group" not in df.columns:
    if "annual_inc" in df.columns:
        df["income_group"] = pd.qcut(
            df["annual_inc"], 4, labels=["Low", "Lower-Mid", "Upper-Mid", "High"]
        )
    else:
        df["income_group"] = "Unknown"

# prediction column (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ loan_status ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°)
if "prediction" not in df.columns:
    df["prediction"] = df["loan_status"]

# Default rate by income group
default_by_income = (
    df.groupby("income_group", observed=False)["loan_status"]
      .mean()
      .reset_index()
      .rename(columns={"loan_status": "Default Rate"})
)

# TPR & FPR by income group
metrics_by_group = []
for group in df["income_group"].unique():
    subset = df[df["income_group"] == group]
    TP = ((subset["loan_status"] == 1) & (subset["prediction"] == 1)).sum()
    FN = ((subset["loan_status"] == 1) & (subset["prediction"] == 0)).sum()
    FP = ((subset["loan_status"] == 0) & (subset["prediction"] == 1)).sum()
    TN = ((subset["loan_status"] == 0) & (subset["prediction"] == 0)).sum()
    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0
    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0
    metrics_by_group.append({"Income Group": str(group), "TPR": TPR, "FPR": FPR})
df_fairness = pd.DataFrame(metrics_by_group)

# Summary metrics (‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏Ñ‡πà‡∏≠‡∏¢‡πÅ‡∏ó‡∏ô)
group_metrics = {
    "default_rate": float(df["loan_status"].mean()),
    "reject_rate": 0.30,
    "dir": 1.25
}

# PDP Mock Data (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á)
pdp_data = pd.DataFrame({
    "Value": list(range(10)),
    "Prediction": [0.2, 0.25, 0.3, 0.33, 0.31, 0.35, 0.36, 0.32, 0.3, 0.28]
})

# Feature definitions (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ä‡∏∏‡∏î‡∏™‡∏±‡πâ‡∏ô ‡πÜ)
if feature_defs_csv is not None and {"Feature","Description"}.issubset(set(feature_defs_csv.columns)):
    df_def = feature_defs_csv[["Feature","Description"]].copy()
else:
    feature_descriptions = [
        {"Feature": "loan_amnt", "Description": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡∏Å‡∏π‡πâ‡∏Ç‡∏≠"},
        {"Feature": "term", "Description": "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏á‡∏¥‡∏ô‡∏Å‡∏π‡πâ"},
        {"Feature": "int_rate", "Description": "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢"},
        {"Feature": "installment", "Description": "‡∏¢‡∏≠‡∏î‡∏ú‡πà‡∏≠‡∏ô‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô"},
        {"Feature": "grade", "Description": "‡πÄ‡∏Å‡∏£‡∏î‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï"},
        {"Feature": "annual_inc", "Description": "‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ï‡πà‡∏≠‡∏õ‡∏µ"},
        {"Feature": "loan_status", "Description": "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠"},
        {"Feature": "dti", "Description": "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏µ‡πâ‡∏™‡∏¥‡∏ô"},
        {"Feature": "revol_bal", "Description": "‡∏´‡∏ô‡∏µ‡πâ‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô"},
        {"Feature": "revol_util", "Description": "‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (%)"},
    ]
    df_def = pd.DataFrame(feature_descriptions)

# ========== (Option) Train and Evaluate Models ==========
# ‡∏£‡∏±‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏ö‡∏≤ ‡πÜ ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
try:
    from xgboost import XGBClassifier
    HAS_XGB = True
except Exception:
    HAS_XGB = False

df_num = df.select_dtypes(include=[np.number]).copy()
df_num = df_num.drop(columns=[c for c in ["prediction"] if c in df_num.columns], errors="ignore")

results = []
try:
    if "loan_status" in df_num.columns and df_num.shape[1] > 1:
        X = df_num.drop(columns=["loan_status"])
        y = df_num["loan_status"]
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y if y.nunique()==2 else None
        )

        models = {
            "Random Forest": RandomForestClassifier(n_estimators=200, random_state=42),
            "Neural Network": MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=300, random_state=42)
        }
        if HAS_XGB:
            models["XGBoost"] = XGBClassifier(
                n_estimators=200, max_depth=4, learning_rate=0.1,
                subsample=0.8, colsample_bytree=0.8, eval_metric="logloss", random_state=42
            )

        for name, model in models.items():
            model.fit(X_train, y_train)
            preds = model.predict(X_test)
            acc = accuracy_score(y_test, preds)
            prec = precision_score(y_test, preds, zero_division=0)
            rec = recall_score(y_test, preds, zero_division=0)
            auc = roc_auc_score(y_test, preds) if y.nunique()==2 else np.nan
            results.append({
                "Model": name,
                "Accuracy": round(acc, 3),
                "Precision": round(prec, 3),
                "Recall": round(rec, 3),
                "AUC": round(auc, 3) if not np.isnan(auc) else "NA"
            })
except Exception as e:
    results = [{"Model": "Error", "Accuracy": "-", "Precision": "-", "Recall": "-", "AUC": str(e)}]

df_results = pd.DataFrame(results)

# ========== Dash App (layout ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°) ==========
app = Dash(__name__, external_stylesheets=[dbc.themes.DARKLY])
server = app.server  # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Render

app.layout = dbc.Container([
    html.H2("Lending Club Loan Dashboard", style={'textAlign': 'center', 'marginTop': '20px'}),

    dbc.Tabs([
        # ----- Tab 1: Model Explainability -----
        dbc.Tab(label='Model Explainability', children=[
            html.Br(),
            html.H4("Feature Importance", id="fi-label"),
            dbc.Tooltip("‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå", target="fi-label"),
            dcc.Graph(
                figure=(
                    px.bar(
                        feature_importance.head(10), x='Feature', y='Importance',
                        color='Importance', color_continuous_scale='Blues'
                    )
                    if (feature_importance is not None and
                        {"Feature","Importance"}.issubset(set(feature_importance.columns)))
                    else px.bar(pd.DataFrame({"Feature":[],"Importance":[]}), x="Feature", y="Importance")
                )
            ),

            html.H4("Partial Dependence Plot", id="pdp-label"),
            dbc.Tooltip("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå", target="pdp-label"),
            dcc.Graph(figure=px.line(pdp_data, x='Value', y='Prediction')),

            html.H5("TPR & FPR by Income Group", id="roc-label"),
            dbc.Tooltip("TPR/FPR ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏°", target="roc-label"),
            dcc.Graph(
                figure=px.bar(
                    df_fairness.melt(id_vars='Income Group', var_name='Metric', value_name='Rate'),
                    x='Income Group', y='Rate', color='Metric', barmode='group'
                )
            ),
        ]),

        # ----- Tab 2: Fairness & Transparency -----
        dbc.Tab(label='Fairness & Transparency', children=[
            html.Br(),
            dbc.Row([
                dbc.Col(html.Div([
                    html.H6("Default Rate"),
                    html.H3(f"{group_metrics['default_rate']*100:.1f}%")
                ]), width=4),
                dbc.Col(html.Div([
                    html.H6("DIR"),
                    html.H3(f"{group_metrics['dir']:.2f}")
                ]), width=4),
                dbc.Col(html.Div([
                    html.H6("Reject Rate"),
                    html.H3(f"{group_metrics['reject_rate']*100:.0f}%")
                ]), width=4),
            ]),
            html.Hr(),
            html.H5("Default Rate by Income Group"),
            dcc.Graph(
                figure=px.bar(
                    default_by_income, x='income_group', y='Default Rate',
                    color='Default Rate', color_continuous_scale='Reds'
                )
            ),
        ]),

        # ----- Tab 3: Model Performance -----
        dbc.Tab(label='Model Performance', children=[
            html.Br(),
            html.H4("‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•", style={'marginTop': '5px'}),
            dash_table.DataTable(
                columns=[{"name": i, "id": i} for i in df_results.columns],
                data=df_results.to_dict('records'),
                style_table={'overflowX': 'auto'},
                style_cell={'textAlign': 'center'},
                style_header={'backgroundColor': 'rgb(30, 30, 30)', 'color': 'white'},
                style_data={'backgroundColor': 'rgb(50, 50, 50)', 'color': 'white'}
            )
        ]),

        # ----- Tab 4: Feature Definitions -----
        dbc.Tab(label='Feature Definitions', children=[
            html.Br(),
            dbc.Input(id='search-input', placeholder="üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå...", debounce=True),
            html.Div(id='feature-table', className="mt-3")
        ]),
    ])
], fluid=True)

# ========== Callback: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå ==========
@app.callback(
    Output('feature-table', 'children'),
    Input('search-input', 'value')
)
def update_table(search_value):
    filtered = df_def.copy()
    if search_value:
        filtered = filtered[filtered['Feature'].astype(str).str.contains(str(search_value), case=False, na=False)]
    if filtered.empty:
        return html.P("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤", style={"color": "red"})
    return dbc.Table.from_dataframe(filtered, striped=True, bordered=True, hover=True)

# ========== Run ==========
if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=int(os.environ.get('PORT', 8050)))
